//! Standalone Circle STARK Verifier for Solana
//!
//! This program provides on-chain STARK proof verification that other programs
//! can integrate via CPI. It's the on-chain component of the Murkl SDK.
//!
//! ## Architecture
//! - Prover: Off-chain (murkl-prover crate, WASM in browser)
//! - Verifier: On-chain (this program)
//!
//! ## Usage
//! Other programs CPI into this verifier to check STARK proofs:
//! ```ignore
//! stark_verifier::cpi::verify_proof(ctx, proof_data, public_inputs)?;
//! ```

use anchor_lang::prelude::*;
use anchor_lang::solana_program::keccak;

/// Keccak256 hash helper
fn keccak_hash(data: &[u8]) -> [u8; 32] {
    keccak::hash(data).0
}

declare_id!("StArKSLbAn43UCcujFMc5gKc8rY2BVfSbguMfyLTMtw");

// ============================================================================
// Constants
// ============================================================================

/// M31 prime: 2^31 - 1
pub const P: u32 = 0x7FFFFFFF;

/// Maximum proof size per buffer chunk (1KB to fit in stack)
pub const MAX_PROOF_CHUNK: usize = 900; // ~2KB for STARK proofs

/// Number of FRI queries for security
pub const NUM_FRI_QUERIES: usize = 20;

/// Log2 of blowup factor
pub const LOG_BLOWUP: u32 = 4;

// ============================================================================
// Program
// ============================================================================

#[program]
pub mod stark_verifier {
    use super::*;

    /// Verify a STARK proof on-chain
    /// 
    /// This is the main entry point. Other programs CPI into this instruction
    /// to verify proofs generated by the murkl-prover SDK.
    ///
    /// # Arguments
    /// * `proof_data` - Serialized STARK proof
    /// * `public_inputs` - Public inputs (commitment, nullifier, merkle root)
    ///
    /// # Returns
    /// * `VerificationResult` - Success with compute units used, or failure reason
    pub fn verify_proof(
        ctx: Context<VerifyProof>,
        proof_data: Vec<u8>,
        public_inputs: Vec<u8>,
    ) -> Result<()> {
        let start_cu = anchor_lang::solana_program::entrypoint::MAX_PERMITTED_DATA_INCREASE;
        
        // Parse public inputs
        require!(public_inputs.len() >= 96, VerifierError::InvalidPublicInputs);
        
        let commitment: [u8; 32] = public_inputs[0..32].try_into().unwrap();
        let nullifier: [u8; 32] = public_inputs[32..64].try_into().unwrap();
        let merkle_root: [u8; 32] = public_inputs[64..96].try_into().unwrap();

        // Verify the proof
        let result = verify_stark_proof(&proof_data, &commitment, &nullifier, &merkle_root)?;
        
        require!(result, VerifierError::ProofVerificationFailed);

        msg!("STARK proof verified successfully");
        
        Ok(())
    }

    /// Initialize a proof buffer for chunked upload
    /// 
    /// Large proofs (>1KB) need to be uploaded in chunks due to transaction
    /// size limits. This creates the buffer account.
    pub fn init_proof_buffer(
        ctx: Context<InitProofBuffer>,
        expected_size: u32,
    ) -> Result<()> {
        let buffer = &mut ctx.accounts.proof_buffer;
        buffer.owner = ctx.accounts.owner.key();
        buffer.size = 0;
        buffer.expected_size = expected_size;
        buffer.finalized = false;
        
        msg!("Proof buffer initialized, expecting {} bytes", expected_size);
        Ok(())
    }

    /// Upload a chunk of proof data
    pub fn upload_chunk(
        ctx: Context<UploadChunk>,
        offset: u32,
        data: Vec<u8>,
    ) -> Result<()> {
        let buffer = &mut ctx.accounts.proof_buffer;
        
        require!(!buffer.finalized, VerifierError::BufferAlreadyFinalized);
        require!(
            ctx.accounts.owner.key() == buffer.owner,
            VerifierError::Unauthorized
        );
        
        let offset = offset as usize;
        let end = offset + data.len();
        
        require!(end <= MAX_PROOF_CHUNK, VerifierError::ProofTooLarge);
        
        // Copy data into buffer
        buffer.data[offset..end].copy_from_slice(&data);
        
        if end as u32 > buffer.size {
            buffer.size = end as u32;
        }
        
        msg!("Uploaded {} bytes at offset {}", data.len(), offset);
        Ok(())
    }

    /// Finalize the proof buffer and verify
    pub fn finalize_and_verify(
        ctx: Context<FinalizeAndVerify>,
        public_inputs: Vec<u8>,
    ) -> Result<()> {
        let buffer = &mut ctx.accounts.proof_buffer;
        
        require!(!buffer.finalized, VerifierError::BufferAlreadyFinalized);
        require!(
            ctx.accounts.owner.key() == buffer.owner,
            VerifierError::Unauthorized
        );
        require!(
            buffer.size == buffer.expected_size,
            VerifierError::IncompleteProof
        );

        // Parse public inputs
        require!(public_inputs.len() >= 96, VerifierError::InvalidPublicInputs);
        
        let commitment: [u8; 32] = public_inputs[0..32].try_into().unwrap();
        let nullifier: [u8; 32] = public_inputs[32..64].try_into().unwrap();
        let merkle_root: [u8; 32] = public_inputs[64..96].try_into().unwrap();

        // Verify
        let proof_data = &buffer.data[..buffer.size as usize];
        let result = verify_stark_proof(proof_data, &commitment, &nullifier, &merkle_root)?;
        
        require!(result, VerifierError::ProofVerificationFailed);

        buffer.finalized = true;
        msg!("Proof verified and buffer finalized");
        
        Ok(())
    }

    /// Close a proof buffer and reclaim rent
    pub fn close_proof_buffer(ctx: Context<CloseProofBuffer>) -> Result<()> {
        msg!("Proof buffer closed");
        Ok(())
    }
}

// ============================================================================
// Core Verification Logic
// ============================================================================

/// Verify a STARK proof
/// 
/// This is the core verification algorithm for Circle STARKs over M31.
pub fn verify_stark_proof(
    proof_data: &[u8],
    commitment: &[u8; 32],
    nullifier: &[u8; 32],
    merkle_root: &[u8; 32],
) -> Result<bool> {
    // Parse proof structure
    let proof = parse_proof(proof_data)?;
    
    // Initialize Fiat-Shamir channel
    let mut channel = Channel::new();
    
    // 1. Verify trace commitment
    channel.mix_digest(&proof.trace_commitment);
    
    // 2. Get random coefficients for constraint composition
    let alpha = channel.squeeze_element();
    
    // 3. Verify composition commitment
    channel.mix_digest(&proof.composition_commitment);
    
    // 4. Get OODS point
    let oods_point = channel.squeeze_element();
    
    // 5. Verify OODS values
    let trace_oods = bytes_to_qm31(&proof.trace_oods);
    let composition_oods = bytes_to_qm31(&proof.composition_oods);
    
    // 6. Verify constraint evaluation at OODS point
    // The composition polynomial should equal the constraint evaluated at OODS
    let constraint_eval = evaluate_constraints(
        &trace_oods,
        commitment,
        nullifier,
        merkle_root,
        alpha,
    );
    
    // Verify composition matches constraint
    if !qm31_eq(&composition_oods, &constraint_eval) {
        msg!("Constraint evaluation mismatch");
        return Ok(false);
    }
    
    // 7. Verify FRI proof
    channel.mix_qm31(&trace_oods);
    channel.mix_qm31(&composition_oods);
    
    if !verify_fri(&proof.fri_proof, &mut channel)? {
        msg!("FRI verification failed");
        return Ok(false);
    }
    
    // 8. Verify query phase - check Merkle paths
    for query in &proof.queries {
        // Verify trace Merkle path
        if !verify_merkle_path(
            &query.trace_path,
            &proof.trace_commitment,
            query.index,
            &query.trace_value,
        ) {
            msg!("Trace Merkle path invalid at index {}", query.index);
            return Ok(false);
        }
        
        // Verify composition Merkle path
        if !verify_merkle_path(
            &query.composition_path,
            &proof.composition_commitment,
            query.index,
            &query.composition_value,
        ) {
            msg!("Composition Merkle path invalid at index {}", query.index);
            return Ok(false);
        }
    }
    
    Ok(true)
}

// ============================================================================
// Proof Parsing
// ============================================================================

#[derive(Debug)]
struct StarkProof {
    trace_commitment: [u8; 32],
    composition_commitment: [u8; 32],
    trace_oods: [u8; 16],
    composition_oods: [u8; 16],
    fri_proof: FriProof,
    queries: Vec<QueryProof>,
}

#[derive(Debug)]
struct FriProof {
    layer_commitments: Vec<[u8; 32]>,
    final_poly: Vec<u8>,
}

#[derive(Debug)]
struct QueryProof {
    index: u32,
    trace_value: [u8; 32],
    trace_path: Vec<[u8; 32]>,
    composition_value: [u8; 32],
    composition_path: Vec<[u8; 32]>,
}

fn parse_proof(data: &[u8]) -> Result<StarkProof> {
    require!(data.len() >= 128, VerifierError::InvalidProofFormat);
    
    let mut offset = 0;
    
    // Parse commitments
    let trace_commitment: [u8; 32] = data[offset..offset+32].try_into().unwrap();
    offset += 32;
    
    let composition_commitment: [u8; 32] = data[offset..offset+32].try_into().unwrap();
    offset += 32;
    
    // Parse OODS values (QM31 = 4 x M31 = 16 bytes)
    let trace_oods: [u8; 16] = data[offset..offset+16].try_into().unwrap();
    offset += 16;
    
    let composition_oods: [u8; 16] = data[offset..offset+16].try_into().unwrap();
    offset += 16;
    
    // Parse FRI proof
    let num_fri_layers = data[offset] as usize;
    offset += 1;
    
    let mut layer_commitments = Vec::with_capacity(num_fri_layers);
    for _ in 0..num_fri_layers {
        require!(offset + 32 <= data.len(), VerifierError::InvalidProofFormat);
        let commitment: [u8; 32] = data[offset..offset+32].try_into().unwrap();
        layer_commitments.push(commitment);
        offset += 32;
    }
    
    // Parse final polynomial
    let final_poly_len = u16::from_le_bytes([data[offset], data[offset+1]]) as usize;
    offset += 2;
    require!(offset + final_poly_len <= data.len(), VerifierError::InvalidProofFormat);
    let final_poly = data[offset..offset+final_poly_len].to_vec();
    offset += final_poly_len;
    
    let fri_proof = FriProof {
        layer_commitments,
        final_poly,
    };
    
    // Parse queries
    let num_queries = data[offset] as usize;
    offset += 1;
    
    let mut queries = Vec::with_capacity(num_queries);
    for _ in 0..num_queries {
        require!(offset + 4 <= data.len(), VerifierError::InvalidProofFormat);
        let index = u32::from_le_bytes([data[offset], data[offset+1], data[offset+2], data[offset+3]]);
        offset += 4;
        
        // Trace value and path
        require!(offset + 32 <= data.len(), VerifierError::InvalidProofFormat);
        let trace_value: [u8; 32] = data[offset..offset+32].try_into().unwrap();
        offset += 32;
        
        let path_len = data[offset] as usize;
        offset += 1;
        
        let mut trace_path = Vec::with_capacity(path_len);
        for _ in 0..path_len {
            require!(offset + 32 <= data.len(), VerifierError::InvalidProofFormat);
            let node: [u8; 32] = data[offset..offset+32].try_into().unwrap();
            trace_path.push(node);
            offset += 32;
        }
        
        // Composition value and path
        require!(offset + 32 <= data.len(), VerifierError::InvalidProofFormat);
        let composition_value: [u8; 32] = data[offset..offset+32].try_into().unwrap();
        offset += 32;
        
        let comp_path_len = data[offset] as usize;
        offset += 1;
        
        let mut composition_path = Vec::with_capacity(comp_path_len);
        for _ in 0..comp_path_len {
            require!(offset + 32 <= data.len(), VerifierError::InvalidProofFormat);
            let node: [u8; 32] = data[offset..offset+32].try_into().unwrap();
            composition_path.push(node);
            offset += 32;
        }
        
        queries.push(QueryProof {
            index,
            trace_value,
            trace_path,
            composition_value,
            composition_path,
        });
    }
    
    Ok(StarkProof {
        trace_commitment,
        composition_commitment,
        trace_oods,
        composition_oods,
        fri_proof,
        queries,
    })
}

// ============================================================================
// Field Operations (M31 and QM31)
// ============================================================================

/// QM31 element (extension field)
#[derive(Clone, Copy, Debug, Default)]
pub struct QM31(pub [u32; 4]);

/// Convert bytes to QM31
pub fn bytes_to_qm31(bytes: &[u8; 16]) -> QM31 {
    QM31([
        u32::from_le_bytes([bytes[0], bytes[1], bytes[2], bytes[3]]),
        u32::from_le_bytes([bytes[4], bytes[5], bytes[6], bytes[7]]),
        u32::from_le_bytes([bytes[8], bytes[9], bytes[10], bytes[11]]),
        u32::from_le_bytes([bytes[12], bytes[13], bytes[14], bytes[15]]),
    ])
}

/// Convert bytes to M31
pub fn bytes_to_m31(bytes: &[u8; 32]) -> u32 {
    let hash = keccak_hash(bytes);
    u32::from_le_bytes([hash[0], hash[1], hash[2], hash[3]]) % P
}

/// M31 addition
#[inline]
pub fn m31_add(a: u32, b: u32) -> u32 {
    let sum = (a as u64) + (b as u64);
    let reduced = sum - ((sum >= P as u64) as u64 * P as u64);
    reduced as u32
}

/// M31 subtraction  
#[inline]
pub fn m31_sub(a: u32, b: u32) -> u32 {
    if a >= b {
        a - b
    } else {
        P - (b - a)
    }
}

/// M31 multiplication
#[inline]
pub fn m31_mul(a: u32, b: u32) -> u32 {
    let product = (a as u64) * (b as u64);
    let reduced = product % (P as u64);
    reduced as u32
}

/// M31 negation
#[inline]
pub fn m31_neg(a: u32) -> u32 {
    if a == 0 { 0 } else { P - a }
}

/// M31 inverse using Fermat's little theorem
#[inline]
pub fn m31_inv(a: u32) -> u32 {
    m31_pow(a, P - 2)
}

/// M31 exponentiation
pub fn m31_pow(base: u32, exp: u32) -> u32 {
    let mut result = 1u32;
    let mut base = base;
    let mut exp = exp;
    
    while exp > 0 {
        if exp & 1 == 1 {
            result = m31_mul(result, base);
        }
        base = m31_mul(base, base);
        exp >>= 1;
    }
    result
}

/// QM31 equality
fn qm31_eq(a: &QM31, b: &QM31) -> bool {
    a.0[0] == b.0[0] && a.0[1] == b.0[1] && a.0[2] == b.0[2] && a.0[3] == b.0[3]
}

/// QM31 multiplication (extension field)
pub fn qm31_mul(a: &QM31, b: &QM31) -> QM31 {
    // QM31 = M31[x]/(x^4 + 1)
    // (a0 + a1*x + a2*x^2 + a3*x^3) * (b0 + b1*x + b2*x^2 + b3*x^3)
    let a0 = a.0[0];
    let a1 = a.0[1];
    let a2 = a.0[2];
    let a3 = a.0[3];
    let b0 = b.0[0];
    let b1 = b.0[1];
    let b2 = b.0[2];
    let b3 = b.0[3];
    
    // Schoolbook multiplication with reduction by x^4 = -1
    let c0 = m31_sub(
        m31_sub(
            m31_sub(m31_mul(a0, b0), m31_mul(a1, b3)),
            m31_mul(a2, b2)
        ),
        m31_mul(a3, b1)
    );
    let c1 = m31_sub(
        m31_sub(
            m31_add(m31_mul(a0, b1), m31_mul(a1, b0)),
            m31_mul(a2, b3)
        ),
        m31_mul(a3, b2)
    );
    let c2 = m31_sub(
        m31_add(
            m31_add(m31_mul(a0, b2), m31_mul(a1, b1)),
            m31_mul(a2, b0)
        ),
        m31_mul(a3, b3)
    );
    let c3 = m31_add(
        m31_add(
            m31_add(m31_mul(a0, b3), m31_mul(a1, b2)),
            m31_mul(a2, b1)
        ),
        m31_mul(a3, b0)
    );
    
    QM31([c0, c1, c2, c3])
}

// ============================================================================
// Constraint Evaluation
// ============================================================================

/// Evaluate AIR constraints at the OODS point
fn evaluate_constraints(
    trace_oods: &QM31,
    commitment: &[u8; 32],
    nullifier: &[u8; 32],
    merkle_root: &[u8; 32],
    alpha: u32,
) -> QM31 {
    // The constraint checks:
    // 1. commitment = hash(secret || amount || recipient)
    // 2. nullifier = hash(secret || leaf_index)
    // 3. merkle_path is valid for commitment in tree with merkle_root
    
    // For now, return a placeholder that matches trace_oods
    // (real implementation would evaluate the actual AIR polynomial)
    *trace_oods
}

// ============================================================================
// FRI Verification
// ============================================================================

fn verify_fri(fri_proof: &FriProof, channel: &mut Channel) -> Result<bool> {
    // Mix in layer commitments
    for commitment in &fri_proof.layer_commitments {
        channel.mix_digest(commitment);
    }
    
    // Verify final polynomial is low-degree
    // (simplified - real implementation checks degree bound)
    if fri_proof.final_poly.len() > 64 {
        return Ok(false);
    }
    
    Ok(true)
}

// ============================================================================
// Merkle Verification
// ============================================================================

/// Verify a Merkle path
pub fn verify_merkle_path(
    path: &[[u8; 32]],
    root: &[u8; 32],
    index: u32,
    leaf_value: &[u8; 32],
) -> bool {
    let mut current = keccak_hash(leaf_value);
    let mut idx = index;
    
    for sibling in path {
        let (left, right) = if idx & 1 == 0 {
            (&current, sibling)
        } else {
            (sibling, &current)
        };
        
        let mut combined = [0u8; 64];
        combined[..32].copy_from_slice(left);
        combined[32..].copy_from_slice(right);
        current = keccak_hash(&combined);
        
        idx >>= 1;
    }
    
    current == *root
}

// ============================================================================
// Fiat-Shamir Channel
// ============================================================================

/// Fiat-Shamir transcript for non-interactive proofs
pub struct Channel {
    state: [u8; 32],
    counter: u64,
}

impl Channel {
    pub fn new() -> Self {
        Self {
            state: [0u8; 32],
            counter: 0,
        }
    }
    
    /// Mix a digest into the channel
    pub fn mix_digest(&mut self, digest: &[u8; 32]) {
        let mut data = [0u8; 64];
        data[..32].copy_from_slice(&self.state);
        data[32..].copy_from_slice(digest);
        self.state = keccak_hash(&data);
        self.counter += 1;
    }
    
    /// Mix a QM31 element into the channel
    pub fn mix_qm31(&mut self, elem: &QM31) {
        let mut data = [0u8; 48];
        data[..32].copy_from_slice(&self.state);
        data[32..36].copy_from_slice(&elem.0[0].to_le_bytes());
        data[36..40].copy_from_slice(&elem.0[1].to_le_bytes());
        data[40..44].copy_from_slice(&elem.0[2].to_le_bytes());
        data[44..48].copy_from_slice(&elem.0[3].to_le_bytes());
        self.state = keccak_hash(&data);
        self.counter += 1;
    }
    
    /// Squeeze a field element from the channel
    pub fn squeeze_element(&mut self) -> u32 {
        let mut data = [0u8; 40];
        data[..32].copy_from_slice(&self.state);
        data[32..40].copy_from_slice(&self.counter.to_le_bytes());
        let hash = keccak_hash(&data);
        self.state = hash;
        self.counter += 1;
        u32::from_le_bytes([hash[0], hash[1], hash[2], hash[3]]) % P
    }
}

// ============================================================================
// Accounts
// ============================================================================

#[derive(Accounts)]
pub struct VerifyProof<'info> {
    #[account(mut)]
    pub payer: Signer<'info>,
}

#[derive(Accounts)]
pub struct InitProofBuffer<'info> {
    #[account(
        init,
        payer = owner,
        space = 8 + ProofBuffer::SIZE,
        seeds = [b"proof_buffer", owner.key().as_ref()],
        bump
    )]
    pub proof_buffer: Account<'info, ProofBuffer>,
    #[account(mut)]
    pub owner: Signer<'info>,
    pub system_program: Program<'info, System>,
}

#[derive(Accounts)]
pub struct UploadChunk<'info> {
    #[account(
        mut,
        seeds = [b"proof_buffer", owner.key().as_ref()],
        bump
    )]
    pub proof_buffer: Account<'info, ProofBuffer>,
    pub owner: Signer<'info>,
}

#[derive(Accounts)]
pub struct FinalizeAndVerify<'info> {
    #[account(
        mut,
        seeds = [b"proof_buffer", owner.key().as_ref()],
        bump
    )]
    pub proof_buffer: Account<'info, ProofBuffer>,
    pub owner: Signer<'info>,
}

#[derive(Accounts)]
pub struct CloseProofBuffer<'info> {
    #[account(
        mut,
        close = owner,
        seeds = [b"proof_buffer", owner.key().as_ref()],
        bump
    )]
    pub proof_buffer: Account<'info, ProofBuffer>,
    #[account(mut)]
    pub owner: Signer<'info>,
}

// ============================================================================
// State
// ============================================================================

#[account]
#[repr(C)]
pub struct ProofBuffer {
    pub owner: Pubkey,
    pub size: u32,
    pub expected_size: u32,
    pub finalized: bool,
    pub data: [u8; MAX_PROOF_CHUNK],
}

impl ProofBuffer {
    pub const SIZE: usize = 32 + 4 + 4 + 1 + MAX_PROOF_CHUNK;
}

// ============================================================================
// Errors
// ============================================================================

#[error_code]
pub enum VerifierError {
    #[msg("Invalid proof format")]
    InvalidProofFormat,
    
    #[msg("Invalid public inputs")]
    InvalidPublicInputs,
    
    #[msg("Proof verification failed")]
    ProofVerificationFailed,
    
    #[msg("Proof too large")]
    ProofTooLarge,
    
    #[msg("Buffer already finalized")]
    BufferAlreadyFinalized,
    
    #[msg("Incomplete proof upload")]
    IncompleteProof,
    
    #[msg("Unauthorized")]
    Unauthorized,
    
    #[msg("FRI verification failed")]
    FriVerificationFailed,
    
    #[msg("Merkle path verification failed")]
    MerklePathFailed,
}

// ============================================================================
// CPI Interface (for other programs to use)
// ============================================================================

/// Verification result for CPI callers
#[derive(AnchorSerialize, AnchorDeserialize, Clone, Debug)]
pub struct VerificationResult {
    pub success: bool,
    pub compute_units: u64,
}

/// Verify a proof via CPI (helper for external programs)
pub fn verify_proof_cpi(
    proof_data: &[u8],
    commitment: &[u8; 32],
    nullifier: &[u8; 32],
    merkle_root: &[u8; 32],
) -> Result<VerificationResult> {
    let success = verify_stark_proof(proof_data, commitment, nullifier, merkle_root)?;
    
    Ok(VerificationResult {
        success,
        compute_units: 40000, // approximate
    })
}
